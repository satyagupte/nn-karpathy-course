{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "801f7344",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import math\n",
    "import random\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1aea3634",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_bird_names(fname):\n",
    "    names = []\n",
    "    with open(fname, 'r') as fp:\n",
    "        next(fp)\n",
    "        for line in fp:\n",
    "            if \",Aves,\" in line:\n",
    "                toks = line.split(',')\n",
    "                try:\n",
    "                    name = toks[17].lower()\n",
    "                    #remove any non a-z, apostrophe or space\n",
    "                    name = re.sub(r'[^a-z\\s]', '', name)\n",
    "                    name = re.sub(r'\\s+', '_', name)\n",
    "                    name = name.strip()\n",
    "                    if len(name) > 3:\n",
    "                        names.append(name)\n",
    "                except:\n",
    "                    pass\n",
    "    return sorted(list(set(names)))\n",
    "words = read_bird_names(\"/Users/satyajitgupte/code/birds/taxa_english.csv\")\n",
    "random.shuffle(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be1b42a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['yukon_blackcapped_chickadee',\n",
       " 'sonora_largebilled_sparrow',\n",
       " 'empidonax_flycatchers',\n",
       " 'pelzelns_todytyrant',\n",
       " 'varied_tits_and_allies']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08d9667c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(''.join(words))))\n",
    "# +1 for .\n",
    "sz = len(chars) + 1\n",
    "itos = {i+1:s for i,s in enumerate(chars)}\n",
    "itos[0] = '.'\n",
    "stoi = {s:i for i,s in itos.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "559d8146",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(words, block_size=2):\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for word in words:\n",
    "        #print(word)\n",
    "        context = [0]*block_size\n",
    "        for char in word + '.':\n",
    "            ix = stoi[char]\n",
    "            ys.append(ix)\n",
    "            xs.append(context)\n",
    "            #print(f\"{''.join(itos[c] for c in context)}->{itos[ix]}\")\n",
    "            context = context[1:] + [ix]\n",
    "    return torch.tensor(xs), torch.tensor(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "170ca2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "Xtr,Ytr = make_dataset(words[:n1], block_size=3)\n",
    "Xdev,Ydev = make_dataset(words[n1:n2], block_size=3)\n",
    "Xte,Yte = make_dataset(words[n2:], block_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69fe51b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([451757, 3]), torch.Size([56547, 3]), torch.Size([56856, 3]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtr.shape, Xdev.shape, Xte.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d6640c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cmp(s, dt, t):\n",
    "    ex_equals = torch.all(dt == t.grad).item()\n",
    "    approx_equals = torch.allclose(dt, t.grad)\n",
    "    max_diff = (dt - t.grad).abs().max().item()\n",
    "    print(f'{s:15s} | ex:{str(ex_equals):5s} | approx:{str(approx_equals):5s} | maxdiff:{max_diff}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2033eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters =  4212\n"
     ]
    }
   ],
   "source": [
    "n_embd = 10\n",
    "block_size = 3\n",
    "n_hidden = 64\n",
    "\n",
    "C = torch.randn((sz, n_embd))\n",
    "# Layer 1\n",
    "W1 = torch.randn((block_size*n_embd), n_hidden) * 5/3 /(n_embd*block_size)**0.5\n",
    "b1 = torch.randn(n_hidden) * 0.1\n",
    "\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, sz)) * 0.1\n",
    "b2 = torch.randn(sz) * 0.1\n",
    "\n",
    "# BatchNorm params\n",
    "bngain = torch.ones((1, n_hidden)) * 0.1 + 1\n",
    "bnbias = torch.zeros((1, n_hidden)) * 0.1\n",
    "\n",
    "# karapthy inits params (multiply by 0.1) because initing with 0 can hide errors in manual backprop\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "for param in parameters:\n",
    "    param.requires_grad = True\n",
    "print(\"Parameters = \", sum(p.nelement() for p in parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "833bd787",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "n = batch_size\n",
    "ix = torch.randint(0, Xtr.shape[0], (batch_size, ))\n",
    "Xb, Yb = Xtr[ix], Ytr[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e2e5480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward pass - chunkated\n",
    "emb = C[Xb]\n",
    "embcat = emb.view(emb.shape[0], -1) # concat the embs\n",
    "#Layer 1\n",
    "hprebn = embcat @ W1 + b1\n",
    "# Batch Norm\n",
    "bnmeani = (1/n)*hprebn.sum(dim=0, keepdim=True)\n",
    "bndiff = hprebn - bnmeani\n",
    "bndiff2 = bndiff**2\n",
    "bnvar = (1/(n-1))*bndiff2.sum(dim=0, keepdim=True)\n",
    "bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "bnraw = bndiff*bnvar_inv\n",
    "hpreact = bngain * bnraw + bnbias\n",
    "\n",
    "# Non Linearity\n",
    "h = torch.tanh(hpreact)\n",
    "\n",
    "# Linear Layer 2\n",
    "logits = h @ W2 + b2\n",
    "\n",
    "# softmax \n",
    "logits_max = logits.max(1, keepdim=True).values\n",
    "norm_logits = logits - logits_max # subtract max for numerical stability\n",
    "counts = norm_logits.exp()\n",
    "counts_sum = counts.sum(1, keepdim=True)\n",
    "counts_sum_inv = counts_sum**-1\n",
    "probs = counts*counts_sum_inv\n",
    "logprobs = probs.log()\n",
    "loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "# pytorch backward pass\n",
    "for param in parameters:\n",
    "    param.grad = None\n",
    "    \n",
    "for t in [logprobs, probs, counts_sum_inv, counts_sum, counts, norm_logits, logits_max, logits,\n",
    "         h, hpreact, bnraw, bnvar_inv, bnvar, bndiff2, bndiff, bnmeani, hprebn, embcat, emb]:\n",
    "    t.retain_grad()\n",
    "    \n",
    "loss.backward()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "20996c0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3, 10]), torch.Size([28, 10]), torch.Size([32, 3]))"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.shape, C.shape, Xb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "ace48891",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dlogprobs       | ex:True  | approx:True  | maxdiff:0.0\n",
      "dprobs          | ex:True  | approx:True  | maxdiff:0.0\n",
      "dcounts_sum_inv | ex:True  | approx:True  | maxdiff:0.0\n",
      "dcounts_sum     | ex:True  | approx:True  | maxdiff:0.0\n",
      "dcounts         | ex:True  | approx:True  | maxdiff:0.0\n",
      "dnorm_logits    | ex:True  | approx:True  | maxdiff:0.0\n",
      "dlogits_max     | ex:True  | approx:True  | maxdiff:0.0\n",
      "dlogits         | ex:True  | approx:True  | maxdiff:0.0\n",
      "dh              | ex:True  | approx:True  | maxdiff:0.0\n",
      "dW2             | ex:True  | approx:True  | maxdiff:0.0\n",
      "db2             | ex:True  | approx:True  | maxdiff:0.0\n",
      "dhpreact        | ex:True  | approx:True  | maxdiff:0.0\n",
      "dbngain         | ex:True  | approx:True  | maxdiff:0.0\n",
      "dbnraw          | ex:True  | approx:True  | maxdiff:0.0\n",
      "dbnbias         | ex:True  | approx:True  | maxdiff:0.0\n",
      "dbnvar_inv      | ex:True  | approx:True  | maxdiff:0.0\n",
      "dbnvar          | ex:True  | approx:True  | maxdiff:0.0\n",
      "dbndiff2        | ex:True  | approx:True  | maxdiff:0.0\n",
      "dbndiff         | ex:True  | approx:True  | maxdiff:0.0\n",
      "dhprebn         | ex:True  | approx:True  | maxdiff:0.0\n",
      "dbnmeani        | ex:True  | approx:True  | maxdiff:0.0\n",
      "dW1             | ex:True  | approx:True  | maxdiff:0.0\n",
      "db1             | ex:True  | approx:True  | maxdiff:0.0\n",
      "dembcat         | ex:True  | approx:True  | maxdiff:0.0\n",
      "dC              | ex:True  | approx:True  | maxdiff:0.0\n"
     ]
    }
   ],
   "source": [
    "# manual backprop\n",
    "dlogprobs = torch.zeros_like(logprobs)\n",
    "dlogprobs[range(n), Yb] = -1.0/n\n",
    "dprobs = (1/probs) * dlogprobs\n",
    "dcounts_sum_inv = (counts * dprobs).sum(1, keepdim=True)\n",
    "dcounts = counts_sum_inv * dprobs\n",
    "dcounts_sum = (-1 * (counts_sum)**-2) * dcounts_sum_inv\n",
    "dcounts += torch.ones_like(counts) * dcounts_sum\n",
    "dnorm_logits = norm_logits.exp() * dcounts # norm_logits.exp() is just counts, so we can also write as counts * dcounts\n",
    "dlogits = dnorm_logits.clone()\n",
    "dlogits_max = -(dnorm_logits).sum(1, keepdim=True)\n",
    "dlogits += F.one_hot(logits.max(1).indices, dlogits.shape[1]) * dlogits_max\n",
    "dh = dlogits @ W2.T\n",
    "dW2 = h.T @ dlogits\n",
    "db2 = dlogits.sum(0)\n",
    "dhpreact = (1 - h**2) * dh\n",
    "dbngain = (bnraw * dhpreact).sum(0, keepdim=True)\n",
    "dbnraw = (bngain * dhpreact)\n",
    "dbnbias = dhpreact.sum(0, keepdim=True)\n",
    "dbndiff = bnvar_inv * dbnraw \n",
    "dbnvar_inv = (bndiff * dbnraw).sum(0, keepdim=True)\n",
    "dbnvar = (-0.5)*((bnvar+1e-5)**-1.5) * dbnvar_inv\n",
    "dbndiff2 = (1/(n-1)) * torch.ones_like(bndiff2) * dbnvar\n",
    "dbndiff += 2*(bndiff)*dbndiff2\n",
    "dhprebn = dbndiff.clone()\n",
    "dbnmeani = -(dbndiff).sum(0, keepdim=True)\n",
    "dhprebn += (1/n)*(torch.ones_like(hprebn)*dbnmeani)\n",
    "dW1 = embcat.T @ dhprebn\n",
    "db1 = dhprebn.sum(0)\n",
    "dembcat = dhprebn @ W1.T\n",
    "demb = dembcat.view(emb.shape)\n",
    "dC = torch.zeros_like(C)\n",
    "for k in range(Xb.shape[0]):\n",
    "    for j in range(Xb.shape[1]):\n",
    "        ix = Xb[k][j]\n",
    "        dC[ix] += demb[k][j]\n",
    "\n",
    "cmp('dlogprobs', dlogprobs, logprobs)\n",
    "cmp('dprobs', dprobs, probs)\n",
    "cmp('dcounts_sum_inv', dcounts_sum_inv, counts_sum_inv)\n",
    "cmp('dcounts_sum', dcounts_sum, counts_sum)\n",
    "cmp('dcounts', dcounts, counts)\n",
    "cmp('dnorm_logits', dnorm_logits, norm_logits)\n",
    "cmp('dlogits_max', dlogits_max, logits_max)\n",
    "cmp('dlogits', dlogits, logits)\n",
    "cmp('dh', dh, h)\n",
    "cmp('dW2', dW2, W2)\n",
    "cmp('db2', db2, b2)\n",
    "cmp('dhpreact', dhpreact, hpreact)\n",
    "cmp('dbngain', dbngain, bngain)\n",
    "cmp('dbnraw', dbnraw, bnraw)\n",
    "cmp('dbnbias', dbnbias, bnbias)\n",
    "\n",
    "cmp('dbnvar_inv', dbnvar_inv, bnvar_inv)\n",
    "cmp('dbnvar', dbnvar, bnvar)\n",
    "cmp('dbndiff2', dbndiff2, bndiff2)\n",
    "cmp('dbndiff', dbndiff, bndiff)\n",
    "cmp('dhprebn', dhprebn, hprebn)\n",
    "cmp('dbnmeani', dbnmeani, bnmeani )\n",
    "cmp('dW1', dW1, W1)\n",
    "cmp('db1', db1, b1)\n",
    "cmp('dembcat', dembcat, embcat)\n",
    "cmp('dC', dC, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "bba0c06e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5067431926727295"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## exercise 2 - backprop through cross entropy all in one go - directly into dlogits \n",
    "loss_fast = F.cross_entropy(logits, Yb)\n",
    "loss_fast.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "28e4f2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dlogits         | ex:False | approx:True  | maxdiff:4.6566128730773926e-09\n"
     ]
    }
   ],
   "source": [
    "dlogits = F.softmax(logits, 1)\n",
    "dlogits[range(n), Yb] -= 1\n",
    "dlogits/=n\n",
    "\n",
    "cmp('dlogits', dlogits, logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "930ddfd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 28])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "9ff430dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-2.3283e-09, grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogits[0].sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "a7a05eed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2,  6,  2,  6,  2,  5,  6,  1, 22, 16,  1, 16, 15,  5,  1, 24, 20,  2,\n",
       "         9, 19,  9, 19,  4, 15,  2,  8,  5, 10, 17, 15, 13,  6])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "b9c3a86f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x119272b30>"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(4,4))\n",
    "plt.imshow(dlogits.detach(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "ba5d9f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exercise 3 - batch norm in one go \n",
    "hpreact_fast = bngain * (hprebn - hprebn.mean(0, keepdim=True))/(torch.sqrt(hprebn.var(0, keepdim=True, unbiased=True)) + 1e-5) + bnbias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "b48c2040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max diff 1.9073486328125e-05\n"
     ]
    }
   ],
   "source": [
    "print(\"max diff\", (hpreact - hpreact_fast).abs().max().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "f390ef7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4598,  1.2692, -1.5245,  ...,  0.9709, -0.8569,  0.0478],\n",
       "        [ 0.8229, -0.8626,  0.3934,  ..., -0.9928,  0.9970,  1.5302],\n",
       "        [ 0.6999, -0.0329,  0.4582,  ...,  0.9343,  2.0105,  0.6890],\n",
       "        ...,\n",
       "        [ 0.4156, -0.5754,  1.3126,  ...,  1.1792, -0.4452, -1.1641],\n",
       "        [ 0.0340,  0.2886,  2.2573,  ...,  0.2320,  0.6122, -1.6238],\n",
       "        [ 0.2789,  0.2242, -1.6070,  ...,  0.9060, -0.7442,  2.0736]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hpreact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "d82660c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# backprop through batchnorm \n",
    "\n",
    "# before we had\n",
    "# dbnraw = (bngain * dhpreact)\n",
    "# dbnbias = dhpreact.sum(0, keepdim=True)\n",
    "# dbndiff = bnvar_inv * dbnraw \n",
    "# dbnvar_inv = (bndiff * dbnraw).sum(0, keepdim=True)\n",
    "# dbnvar = (-0.5)*((bnvar+1e-5)**-1.5) * dbnvar_inv\n",
    "# dbndiff2 = (1/(n-1)) * torch.ones_like(bndiff2) * dbnvar\n",
    "# dbndiff += 2*(bndiff)*dbndiff2\n",
    "# dhprebn = dbndiff.clone()\n",
    "# dbnmeani = -(dbndiff).sum(0, keepdim=True)\n",
    "# dhprebn += (1/n)*(torch.ones_like(hprebn)*dbnmeani)\n",
    "\n",
    "dhprebn = bngain*bnvar_inv/n * (n*dhpreact - dhpreact.sum(0) - n/(n-1)*bnraw*(dhpreact*bnraw).sum(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "33164511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dhprebn         | ex:False | approx:True  | maxdiff:9.313225746154785e-10\n"
     ]
    }
   ],
   "source": [
    "cmp('dhprebn', dhprebn, hprebn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "c1a986ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters =  4212\n",
      "Iter :0/200000 Loss:3.6234\n",
      "Iter :10000/200000 Loss:2.3891\n",
      "Iter :20000/200000 Loss:1.9550\n",
      "Iter :30000/200000 Loss:2.3792\n",
      "Iter :40000/200000 Loss:1.6772\n",
      "Iter :50000/200000 Loss:2.6051\n",
      "Iter :60000/200000 Loss:2.1344\n",
      "Iter :70000/200000 Loss:2.2110\n",
      "Iter :80000/200000 Loss:2.2993\n",
      "Iter :90000/200000 Loss:1.5010\n",
      "Iter :100000/200000 Loss:1.4020\n",
      "Iter :110000/200000 Loss:2.0208\n",
      "Iter :120000/200000 Loss:1.9258\n",
      "Iter :130000/200000 Loss:1.8495\n",
      "Iter :140000/200000 Loss:1.7163\n",
      "Iter :150000/200000 Loss:1.8357\n",
      "Iter :160000/200000 Loss:2.0494\n",
      "Iter :170000/200000 Loss:2.1857\n",
      "Iter :180000/200000 Loss:1.9870\n",
      "Iter :190000/200000 Loss:1.8050\n"
     ]
    }
   ],
   "source": [
    "# Exercise 4 - Full optmization with manual backprop\n",
    "\n",
    "n_embd = 10\n",
    "block_size = 3\n",
    "n_hidden = 64\n",
    "\n",
    "C = torch.randn((sz, n_embd))\n",
    "# Layer 1\n",
    "W1 = torch.randn((block_size*n_embd), n_hidden) * 5/3 /(n_embd*block_size)**0.5\n",
    "b1 = torch.randn(n_hidden) * 0.1\n",
    "\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, sz)) * 0.1\n",
    "b2 = torch.randn(sz) * 0.1\n",
    "\n",
    "# BatchNorm params\n",
    "bngain = torch.ones((1, n_hidden)) * 0.1 + 1\n",
    "bnbias = torch.zeros((1, n_hidden)) * 0.1\n",
    "\n",
    "# karapthy inits params (multiply by 0.1) because initing with 0 can hide errors in manual backprop\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "for param in parameters:\n",
    "    param.requires_grad = True\n",
    "print(\"Parameters = \", sum(p.nelement() for p in parameters))\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "n = batch_size\n",
    "max_steps = 200000\n",
    "lossi = []\n",
    "\n",
    "# since we are doing manual bacprop, dont need torch auutograd\n",
    "with torch.no_grad():\n",
    "\n",
    "    for i in range(max_steps):\n",
    "\n",
    "        # get batch \n",
    "        ix = torch.randint(0, Xtr.shape[0], (batch_size, ))\n",
    "        Xb, Yb = Xtr[ix], Ytr[ix]\n",
    "\n",
    "        # forward pass\n",
    "        emb = C[Xb]\n",
    "        embcat = emb.view(emb.shape[0], -1) # concat the embs\n",
    "\n",
    "        # Layer 1\n",
    "        hprebn = embcat @ W1 + b1\n",
    "\n",
    "        # Batch Norm  \n",
    "        bnmean = hprebn.mean(0, keepdim=True)\n",
    "        bnvar = hprebn.var(0, keepdim=True, unbiased=True)\n",
    "        bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "        bnraw = (hprebn - bnmean) * bnvar_inv\n",
    "        hpreact = bngain * bnraw+ bnbias\n",
    "\n",
    "        # Non Linearity\n",
    "        h = torch.tanh(hpreact)\n",
    "        # Linear Layer 2\n",
    "        logits = h @ W2 + b2   \n",
    "        # cross entropy\n",
    "        loss = F.cross_entropy(logits, Yb)\n",
    "\n",
    "\n",
    "        # backprop\n",
    "        for param in parameters:\n",
    "            param.grad = None\n",
    "\n",
    "        \n",
    "        #loss.backward()\n",
    "\n",
    "\n",
    "\n",
    "        # manual backprop\n",
    "        dlogits = F.softmax(logits, 1)\n",
    "        dlogits[range(n), Yb] -= 1\n",
    "        dlogits/=n\n",
    "\n",
    "        # 2nd layer backprop\n",
    "        dh = dlogits @ W2.T\n",
    "        dW2 = h.T @ dlogits\n",
    "        db2 = dlogits.sum(0)\n",
    "        # backprop through tanh\n",
    "        dhpreact = (1.0 - h**2) * dh\n",
    "\n",
    "        #batchnorm backprop\n",
    "        dbngain = (bnraw * dhpreact).sum(0, keepdim=True)\n",
    "        dbnbias = dhpreact.sum(0, keepdim=True)\n",
    "\n",
    "        # I just copied this from karpathy's notebook. \n",
    "        dhprebn = bngain*bnvar_inv/n * (n*dhpreact - dhpreact.sum(0) - n/(n-1)*bnraw*(dhpreact*bnraw).sum(0))\n",
    "\n",
    "        # 1st Layer \n",
    "        dembcat = dhprebn @ W1.T\n",
    "        dW1 = embcat.T @ dhprebn\n",
    "        db1 = dhprebn.sum(0)\n",
    "\n",
    "\n",
    "        # backprop through embs \n",
    "\n",
    "        demb = dembcat.view(emb.shape)\n",
    "        dC = torch.zeros_like(C)\n",
    "        for k in range(Xb.shape[0]):\n",
    "            for j in range(Xb.shape[1]):\n",
    "                ix = Xb[k][j]\n",
    "                dC[ix] += demb[k][j]\n",
    "\n",
    "        grads = [dC, dW1, db1, dW2, db2, dbngain, dbnbias]\n",
    "        # update grads\n",
    "        lr = 0.1 if i < 100000 else 0.01\n",
    "        for p, grad in zip(parameters, grads):\n",
    "            #cmp(\"shape:{}\".format(grad.shape), grad, p)\n",
    "\n",
    "            #p.data += -lr*p.grad\n",
    "            #print(p.shape, grad.shape)\n",
    "            p.data += -lr*grad\n",
    "\n",
    "        if i % 10000 == 0:\n",
    "            print(\"Iter :{}/{} Loss:{:.4f}\".format(i, max_steps, loss.item()))\n",
    "        lossi.append(loss.item())\n",
    "        #break\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "1817009a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11f84b190>]"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAAsTAAALEwEAmpwYAAAopElEQVR4nO3deXhU5d3G8e8zM1nITjbWkLBvIquyuOFWEa3UpX3dtXWtrdWqb7Vaba21an1rrdZdq6VatwKKuIIgCAgYIGwJhB0SQghkJSHrPO8fM4lJSCBIkslM7s915WJy5mTmN2eGO09+5znnGGstIiLi/xy+LkBERFqHAl1EJEAo0EVEAoQCXUQkQCjQRUQChMtXTxwfH29TUlJ89fQiIn5p5cqV+621CU3d57NAT0lJITU11VdPLyLil4wxO5u7Ty0XEZEAoUAXEQkQCnQRkQChQBcRCRAKdBGRAKFAFxEJEAp0EZEA4XeBvmlvCX/9YhP7D1b4uhQRkQ7F7wJ9a95Bnp2/RYEuItKI3wV6kNNTcnWNLswhIlKfHwa6AaCyxu3jSkREOha/C/Rg7wi9qlqBLiJSn98FepDLG+hquYiINOB/gV47QlfLRUSkAT8MdPXQRUSa4neBHqwRuohIk/wu0NVyERFpmv8Feu1O0WrtFBURqc//Al09dBGRJvlfoDvUchERaYr/BbpLh/6LiDTF/wJdLRcRkSb5X6Cr5SIi0iS/C3SHw+ByGAW6iEgjfhfo4JmLrnO5iIg05KeBbqjU2RZFRBrwy0APdjnUchERacQvA93TclGgi4jU58eBrh66iEh9fhroRvPQRUQa8dNAd+gSdCIijfhtoFe71XIREanvqIFujEkyxiwwxqQbYzYYY+5oZr3Jxpg07zoLW7/U7wQ5dWCRiEhjrhasUw3cba1dZYyJBFYaY+Zaa9NrVzDGxADPA1OstbuMMYltU65HkNOheegiIo0cdYRurc2x1q7y3i4BMoBejVa7Ephprd3lXW9faxdan+ahi4gc7ph66MaYFGA0sLzRXYOArsaYr4wxK40x1zbz8zcbY1KNMal5eXnfq2DQtEURkaa0ONCNMRHADOBOa21xo7tdwFjgAuA84EFjzKDGj2GtfdlaO85aOy4hIeF7F60euojI4VrSQ8cYE4QnzN+y1s5sYpUs4IC1thQoNcYsAkYCma1WaT1BTofmoYuINNKSWS4GeA3IsNY+1cxqHwKnGmNcxpgwYDyeXnubCNah/yIih2nJCP0U4BpgnTEmzbvsfqAPgLX2RWtthjHmM2At4AZetdaub4N6gdoDi9RDFxGp76iBbq1dDJgWrPck8GRrFHU0QS710EVEGvPbI0XVQxcRacgvAz3Y6aBa0xZFRBrwy0DX+dBFRA7nl4Huchqq3Ra3TtAlIlLHLwM9yOkpu8qtUbqISC2/DPTg2kBXH11EpI5fBnqQ0zOLUhe5EBH5jn8Guqt2hK5AFxGp5Z+B7m25aC66iMh3/DLQ1UMXETmcXwZ63SwXjdBFROr4aaB7dorqMnQiIt/xz0D37hSt1oFFIiJ1/DLQg9VyERE5jF8Gel0PXS0XEZE6fhnortoeukboIiJ1/DLQNW1RRORwfhnomrYoInI4Pw1077lcFOgiInX8NNC9h/5rp6iISB2/DPRgl3roIiKN+WWgq4cuInI4Pw109dBFRBrz00BXy0VEpDE/D3SN0EVEavlloDsdBqfDKNBFROrxy0AHTx9dh/6LiHzHjwPdQVW1eugiIrX8O9A1QhcRqePHga4euohIfX4c6A710EVE6vHbQA92OjQPXUSkHr8NdM9OUY3QRURq+W2gB7scVFTX+LoMEZEOw28DPSLExcGKal+XISLSYfhtoEeGuigpV6CLiNTy20CPUKCLiDRw1EA3xiQZYxYYY9KNMRuMMXccYd2TjDHVxpjLWrfMw0WFBqnlIiJSj6sF61QDd1trVxljIoGVxpi51tr0+isZY5zAE8AXbVDnYWp76NZajDHt8ZQiIh3aUUfo1toca+0q7+0SIAPo1cSqtwMzgH2tWmEzIkJd1Lgth6o000VEBI6xh26MSQFGA8sbLe8FXAy8cJSfv9kYk2qMSc3LyzvGUhuKDPX8cXFQfXQREeAYAt0YE4FnBH6ntba40d1PA/daa494pI+19mVr7Thr7biEhIRjLra+iBBPoBcr0EVEgJb10DHGBOEJ87estTObWGUc8I63lx0PTDXGVFtrP2itQhuLCg0C0I5RERGvowa68aT0a0CGtfapptax1vatt/4bwJy2DHPw9NABSsqr2vJpRET8RktG6KcA1wDrjDFp3mX3A30ArLUvtk1pR6YeuohIQ0cNdGvtYqDF8wKttdcfT0EtVdtD18FFIiIefnukaKS3h16iHrqICODHgf7dCF09dBER8ONAdzoM4cFO9dBFRLz8NtBBJ+gSEanPrwM9UifoEhGp49eBHhHiolg9dBERwM8DPTJUVy0SEanl94GuHrqIiIdfB3pEiEuzXEREvPw60CNDgzQPXUTEy68DPSLERWllDTVu6+tSRER8zq8Dve4EXdoxKiKiQBcRCRR+HujeE3Spjy4i4t+BXnvVoqIyBbqIiF8HekJkCAB5Byt8XImIiO/5daAnegM9t1iBLiLi14EeExZEsNPBvpJyX5ciIuJzfh3oxhgSIkPYpxG6iIh/BzpAt6gQjdBFRAiAQE+MDFUPXUSEAAj0blEh7CvWCF1ExO8DPTEqlOLyasqranxdioiIT/l/oHunLmrHqIh0dv4f6FGhAORqx6iIdHJ+H+jdojRCFxGBAAj0xEjPCF1TF0Wks/P7QO8aFkSQ02jqooh0en4f6MYYEiNDNUIXkU7P7wMdIDEqhFzNRReRTi4gAr131zCyCg75ugwREZ8KiEBPjvUEelWN29eliIj4TGAEelwYNW7LnkKN0kWk8wqQQA8HYMeBMh9XIiLiOwER6ClxYQDsOlDq40pERHwnIAI9ITKELkFOjdBFpFMLiEA3xtAnNoydCnQR6cSOGujGmCRjzAJjTLoxZoMx5o4m1rnKGLPWGLPOGLPUGDOybcptXnJcGDvVchGRTqwlI/Rq4G5r7TBgAvALY8ywRutsB86w1o4AHgFebt0yjy45Loxd+WW43ba9n1pEpEM4aqBba3Ostau8t0uADKBXo3WWWmsLvN8uA3q3dqFHkxwXTkW1W6fRFZFO65h66MaYFGA0sPwIq90AfNrMz99sjEk1xqTm5eUdy1MfVbJ3pov66CLSWbU40I0xEcAM4E5rbXEz65yJJ9Dvbep+a+3L1tpx1tpxCQkJ36feZqV456LvUqCLSCflaslKxpggPGH+lrV2ZjPrnAi8CpxvrT3QeiW2TI/oUFwOww7tGBWRTqols1wM8BqQYa19qpl1+gAzgWustZmtW2LLuJwOkmLD2JmvEbqIdE4tGaGfAlwDrDPGpHmX3Q/0AbDWvgg8BMQBz3vyn2pr7bhWr/YoPHPRNUIXkc7pqIFurV0MmKOscyNwY2sV9X2lxIWxalcB1lq8v1hERDqNgDhStFafuHBKyqspKKvydSkiIu0uoAI9pW7qotouItL5BFSgay66iHRmARXovbuGYYwCXUQ6p4AK9NAgJz2iQtVyEZFOKaACHaBPXJgOLhKRTingAn1I9yg27i2hRmddFJFOJuACfVRSDGWVNWzeV+LrUkRE2lXABfrIpBgA1uwu9GkdIiLtLeACPSUujKhQF2kKdBHpZAIu0I0xjEyKIW13ka9LERFpVwEX6ACjk2LIzC2hrLLa16WIiLSbgAz0kUkx1Lgt67ObvA6HiEhACshAH94zGoBNexXoItJ5BGSgd4sKISzYybb9OsBIRDqPgAx0Ywx948PZlqdAF5HOIyADHaBvfDjbNUIXkU4kYAO9X0IEWQVlVFTX+LoUEZF2EbiBHh+O28JuXTRaRDqJwA30hHAAtqqPLiKdRMAGekq8J9C37y/FWp15UUQCX8AGelRoEPERIXy6fi8THvuSD9OyfV2SiEibCthAB0/bZc3uQnKLK/jTxxkcrNCpAEQkcAV0oI/vG0u/+HBeuGoMeSUVvLRwq69LEhFpMwEd6Hf/YDDz7jqD80f04IIRPXh9yQ5dyUhEAlZABzqAw2EAOHNIIgcrqtm+/6CPKxIRaRsBH+i1TuztOWHX2iydJ11EAlOnCfT+CRF0CXIq0EUkYHWaQHc6DMN7RrE+W4EuIoGp0wQ6wIje0WzYU0x1jdvXpYiItLrOFei9ojlUVaPTAYhIQOpUgV67Y3TN7kLfFiIi0gY6VaD3i4+gZ3Qos1brNAAiEng6VaA7HIZrJqbwzbYDZOToeqMiElg6VaADXHFyEqFBDh7+aAM3T0/lnRW7fF2SiEir6HSBHhMWzKVjerNsWz7fbDvAfTPX8cicdKy1lFZU883WAzrdroj4JZevC/CFBy4YyuUn9WFoj0j+9HEGry3eTlRoEMu3H2Dp1gO8ePUYppzQw9dliogck6OO0I0xScaYBcaYdGPMBmPMHU2sY4wxzxhjthhj1hpjxrRNua0jLNjFiN7RuJwOfv/DYVw0sid/m5fJ0q0HSIgM4eGP0inVqXZFxM+0ZIReDdxtrV1ljIkEVhpj5lpr0+utcz4w0Ps1HnjB+2+HZ4zhL5edSFWNm5NSYhmZFMOlLyzl0heWcvbQRG4/ayChQU5flykiclRHDXRrbQ6Q471dYozJAHoB9QN9GjDdeprPy4wxMcaYHt6f7fBCg5y8cPXYuu8fvfgEZq7K5rkFW9mVf4hnLh+FMcaHFYqIHN0x7RQ1xqQAo4Hlje7qBeyu932Wd1njn7/ZGJNqjEnNy8s7xlLbz1Xjk5nx80ncO2UIH63Zw/NfeS6MYa3FrfOpi0gH1eJAN8ZEADOAO62132sSt7X2ZWvtOGvtuISEhO/zEO3q1jP6MWV4d55bsIX9Byu4/vVvuXF6qmbBiEiH1KJZLsaYIDxh/pa1dmYTq2QDSfW+7+1d5teMMdz9g0F8nr6Xq19dzsa9JQAs2ryfzL0lZOQU85OTkpjQL87HlYqItGyWiwFeAzKstU81s9ps4FrvbJcJQJG/9M+PZmC3SKaO6MHGvSWM7xtL765d+PW7aTz6SQZz1uZw+cvLmL1mzxEfY21WIUVlVe1UsYh0Vi1puZwCXAOcZYxJ835NNcbcaoy51bvOJ8A2YAvwCnBb25TrG3efO4gzByfwxKUncsfZA8kvrWTqiO6sfuhcBiRG8OrX2xq0YepftzSroIyLn1/KXz7f6IvSRaQTacksl8XAEad4eGe3/KK1iupo+iVE8PpPTwYgOS6M3l3DGJvclWCXg+smJvPghxtYvbuQMX268tQXm/hwzR5m/HwS8REh/HOx58LUX6Tn8si0E+qucVpfQWklXcOD2/tliUiA6XSH/h8vYwwT+8cR7PJsukvG9CYyxMVrX29nX3E5Ly3axs4DZdz13hoKyyp559tdJESGkFdSQVpWIXklFZRX1dQ93ifrchj36DzS9+hkYSJyfBToxyk8xMV1k1L4eF0OV7+2nGq35ZbT+7EoM49Rf5xLWWUNz1w+GpfD8PyCrUx+cgGPf/pd++Wfi7dT47a8tXynD1+FiASCTnkul9b263MHsSu/jNlr9nDJmF7cd/4QBnaLZFd+GX1iw5jYP44J/eKYl5ELwDdbDwCwcW8xqTsLiAp18WHaHu6fOpTwkJa/JW635T8rdnHmkER6xXRpk9cmIv5DI/RW4HQY/vqTkfz54hH87oJhGGO4bGxv7jp3EJeN7Q3AleP70CumCz8a1ZNNuSUUlVXx1rJdBLsc/PUnozhYUc2HaUeeLdPYU3Mz+d0H65n+zY42eFUi4m80Qm8lQU4HV47v0+z9U0f04PwTurNsWz4fpO1h0eY8Zq3O5sIRPThnaCLDekTxuw/Wkbojnwn944gLD8ZaGNYzip7e0femvSUs336AkvJqNu4t4SPvdEn130UEFOjtyhjDqKQYXA7D459u5GBFNVdNSMYYw79vOJnnv9rKf5bvYmajS+T1iulCSnwYS7ceoHZ2ZLeoEP5nXBLVbsv8jblYa496vpmsgjI27S1hQGIEyXHhbfUyRcRHFOjtrEuwkxN6RZO2u5Ah3SMZ0ycGgLiIEB68cBj3Tx3Krvwyig5VUeN2s2Z3Ed/uyGfT3hJuOb0/101KJqZLMF2CPWeA/Pc3O5ixKos9ReWEuByk7ykmPMTF2OSudc9preXxzzby0sJtAPTu2oUvfn06YcFHfvuzCsroFhVKkLN1O3OlFdXcN3Mdd5w9kAGJEa362CKdmQLdB8YldyVtdyFXe0fn9Tkdhr7x342exybH8rNT+zb7WMN7RQOwdMt+/vxJBgXeI1Ifvmg4101KIbe4nD/OSefjtTlcflIS41Jiuef9NTz1RSa/u3BY3eNszi2htLKGUUkxgKe9M/WZrxnaI5Lf/3A48REhJMeGNTmPvr7Xl2zn1a+386+fncSAxMgm1/ly4z4+WrOHyuoaXrpm3BEfrynzN+aSGBnKCd7XLiIeCnQf+NHoXmzbX8qPRh92QspjNrR7FA4DT36+iYKyKv5x5Wg+TNvD72dvYOaqLDblllDjtvzveYO5bXJ/jDGs3lXAa0u2Mzcjl3OHduOm0/txxSvLcBjDst+ejcNheHnRNoKchuyCQ/z4xW8AmNgvjr9fMYrEyFA+37CXlxZu5fpT+nLhCM/VnR7/bCMvL/L8FfDwR+lM/9nJTbaB5qV7Zvt8viGXTXtLiIsI5ul5mazaWciAxAguPLEH5wzt1uQvj4MV1dz21iqSuobxxa9P12mNReoxvjpz4Lhx42xqaqpPnjvQnPvUQjbvO8jJfWN575aJlFfV8NCH69lTWE5KfBg3ndavQc+8tKKaV77exvrsIuZl7CMq1EVxuecKTR/98lTiI4M57YkFXD0hmV+eNYAV2/PJKijjqbmZRIQE8cdpw7l3xloqqtxU1rgZ0j2S3l3DmJeRy7UTk+kTG8afPs5g2qie5JdW8ueLR5AUG0aN2+K2ljGPzGVivziWbNlPRKiLwrIqqt2W8X1j2bzvIHklFYzpE8P7t07C2SjUZ67K4q731gDwxk9PYvLgRLILD/H5+r1cNaEPIa6WXYzkw7RsJvSLo1tUKAB5JRUs2bKfaaN66peEdGjGmJXW2ib/tNUIPQCc0CuazfsO8rNTPK2Z0CAnf7lsZLPrh4e4uPOcQQC8tHArj3+2kf89bzD/98Um5m/cR9GhKixww6l9iY8IYap3BH7GoERunP4tt721ivBgJ1/8+nTWZBXy1NxM5mXk8pspg/n5Gf2pdlv+uzKLT9fvxQC/emc1Px6bxB/nbODsod0oKa/m0rG9Gd8vjlmrs5g6ogdXjU9mQGIE1TVuXl28ncc/3ciizXmcOTixQe2zVmfTK6YL1W43/5i/hZU7C3j16+0cqqohqksQpw+M5zcz1vKrswcypk9XmpK6I5873knjipP78NglIwD48ycZzFqdTXxECKcOjD/Od0TENzRCDwBfbdrH+6lZPHPF6MNGtC1RUl5FZGgQFz+/hAMHK8kpOsQlo3vzxGUnHrbugYMV/OGjdC48sQfnDe8OQFWNm+yCQ6TU6/3Xnt7gi/RcfvX2asAzMye3uIJgl4O0h85tdqdsZbWbCY99yfi+sQ2uJLWvuJwJj33JbZMHEBbi5C+fbcIYOHdoN9ZnFzG4eyQjekXzzPwtdA0LYsbPJ9Ev4fCdrjdNT2Vuei4xYUGsuP8c9pWUc8aTX1HjtozpE8OMn0/SKF06LI3QA9zkwYlMbjSSPRaRoUEAnDU4kb/OzSQ82Mnd5w1qct24iBCevWJ0g2VBTkeDMAfqrsN60cieZOQUU1JexYMXDuONJTtwGHPEGTbBLgcXj+7F9G92cP+sdSzYuI8Te0ezalch4NkHkRTbheTYcE5K6UpiVCiPfZLBa4u3sy67mJFJMWTll3Hrmyv59I7TcToM2/IO8kHaHiJDXMzLyGVUUgxpuwtZvCWPRZn7McDtZw3g2flb+GpTHmcO+f7bU8RXNEKXOhv3FjPl6a+5d8oQfj65v09r2bS3hPOeXgTAGYMS2JxbQr+ECG4/awDjm7igyNqsQi76xxIAXr5mLFU1ll/8ZxV/v3wUGTklvLhwa926oUEOFtwzmSlPf01cRDC7DpQxbVQvHrtkBD/420LKq9zMvv0UEiND2+fFihwDjdClRYZ0j2LeXWfQP8H3Bx0N7h7JI9OG0y8hglMGHL2nPaJXNH1iwyivquGsIYk4jGFI90h+N2s9JRXV/Hhsb34zZQgFZZVYCz2iuzB1RHfeXrGbKcO789APhxHscvD8VWO55IUl3PbmKt69ZeL3amGJ+IpG6BIwVu8qwG0tY5NjAfh8w15u+fdKzh3WjRevHntYOBeVVbEuu4hTBsQ16Jm/s2IX981cxzs3T9DlBaXDOdIIXSfnkoAxuk/XujAH+MGwbrx3y0SebWZncXRYEKcOjD9sB+gPR/Yk2Omomy8v4i8U6BKwjDGc3De2bgdtS4WHuJg0II65Gbnszi/j4Y82NLgoybHKK6lgUWbe9/55kZZSoIs04Zyh3dh5oIyrX1vO60t2kLqj4Jh+3u22VNW4AXj+qy1c9/oK8koqDluv/vVnv4/Za/Zw0/RU5qXn4j7OxzqS+Rtz+cPsDYctt9ZSVuk5KC0zt4Rfvb2akvLWvyB6QWklH6Zl121TaZoCXaQJZw/1TFvceaAMgPV7igDYW1ROS/Y7PTN/M2f/dSFut2XVzgKshcVbGo7S56zdw4l/+Jzt+0uPqbZXv97GT19fwcqdBdz737XM37iPG6enMu25Jfxn+S5+O3Mt17y2nB+/uJRfvb2afy7ezsqd+by5bCdrswrrHqfGe6bOlvxSeWvZLt5YuoOteQcbLH9t8XbGP/olhWWVvJ+6m9lr9vDs/C0tfi2V1W7eWLKdfy7efsT1fvfheu54J43LXljKzgPfba99xeU8t2ALhyq//19QraXoUBU/fnEpq3YVUFBaycXPL+G9b3cftl5O0aEmf7m3Bs1yEWlCj+guXHhiD3p3DeOjNXvYsKeYpVv3c+Ury7loZE8evfiEuvn7TflozR525ZexalcBG7znq1+UuZ+LR/euW+eVRdsorazh/77YxHNXjmlRXVkFZfzl801UVrtZsCmPyFAXX/x6Miu25/OXzzdy/6x1RIW66JsQQYjLwcqdBcxe892FU1wOw+8vGs41E5KZm57LrW+u5IGpQzl9UAK/+e8arp2YwqVjezd4Tmstq3cXAvDZ+r384swBABSXV/Hs/C2UVFSzMDOPxVs8V+L65+LtHDhYyTdb9/PYpScSHxHMG0t2cN2klAYnVCsoreTSF5aybX8pDgMXjuxRN1X0s/V7GZfSlfiIENZmFfLx2hzOGZrItzsKuOFfqcy5/VRcDsMv/7OaFTvysdbyy7MGHra9cooOUVHlPuw4ieNR47Zs2FPEiF7RDfa/LMrM49sdBfzxo3TG94tl9a5C0nYXUlxexcikGPYWlfNlRi5z1uZw3aQUHqx3crzWokAXacY/vCG7Ne8gG/YU8cWGYFwOw5y1e8jMLeHdmycSHRbEgk37uPe/azlQWsnI3tE8/T+j2ZrnGUU+/9VWqt2W+IhgFmXm4XZbHA7D2qxC1mQV0S8hnI/X5jC422aqatz89JS+rN5VwO9nb+C2yQOIDQ/mpUVbGZjomb75+Ya9nse9agxPz8vkjrMHkRQbRlJsGOeP6M7u/EMMSIxosBN4x/5SNu4toX9COH/+JIMHP1jP6KQYlm3zBPDf5mXy1vKd7Mwv4+7315C5r4Tfnj+07ud3Higjv7QSY+DT9Z4wWrO7kLnpuRQdqiI82Ml/V2aRkVPMz07py39X7mb2mmwSI0O54Y1vcRhDZY2bmauz+e35Q7jxtH4AvLp4G9sPlPLQhcP445x05qzJ4Wen9q37RXPO0EReuXYcj3+6kdjwYP72P6NI213INa+t4L4Za3E5HazYkU+f2DBeXLiNIKeDt1fs4rmrxjCsRxT/XraTxz7ZiNNheO+WiQzrGVX3mmrcluJDVXQND/a2jWoID3FxqLKGokNVdI9u+hgEay1/mL2Bfy/byeOXjOCysb1ZtDmP0wYmsHjzfgDSdheyNquQqSO6U1hWxZ8+zqj7+fBgJ9dMTOb6SSnH+/FskqYtihzF0/My+fuXm+kZ3YUBiRH89JQUbpqeyrCe0QxKjGDGqiwGd49iaPdIZq7O5vRBCSzKzCM+Ipj9BysBeGDqUB79JIM5t5/K0B5R3P1eGp9vyGX+PWfww2cX163XK6YLeQcrCHIYSr1thJS4MA6UVlLiPYHarWf0577zh3yv11JQWsnYP83ll2cNZF56LtVuN7vyy6isdvPmDeN5+9vdfL5hL6sfPLfu+ra1J0S7ZEwvZq7KJim2C7vzDwFw/gndCQ9x8d+VWQDMum0SseHBBDkdRIS6+PU7aQS7HNw7ZQiPfpLBlxm5zLrtFJLjwjj1iQWcMTiB564cwwXPfI3LYXjn5omc89RC9pWUU1Vj657zkWnDuWZiCgAPf7SB15fsAODaiclcOzGZH/xtEW4LxnhOTz3lhB48Mied0wbGsznX0yZ688aT607pfNd7acxLz2X+PZP519IdPDt/Cz2jQ9l/sBK3tbx/60TySyt55ett/OPKMcSFB7N8ez4fr83h38t2EhHiokuwk7MGJ/Ju6m5+e/4Qpn+zk6E9ItmWV8rO/DK+vOsMenftQkZOCQVllSREhtA3PvyYd9I3dqRpiwp0kaOYl57LjdM9n9UHLxzGDaf2Zc7aPdz93hpCg5ycPTSRR6adQIjLwVl/XVh3cfDzR3TnpYXb6BMbxoyfT+KkR+fRLSoEl8NBduEhrp+Uwh8uGs6ewkNUVrvJL6vk5ukriQ0P4u2bJvBh2h6qatx158PPzC1h+/5Szhna7bhC4bIXlpJfWsn2A6XccfZATuwdTWW1ZcoJ3Vm27QCXv7yMF64aw8ikGHKKyvlgdTazVmcz5/ZTmfx/XxEfEczDF52Ay2kY3zeWpVsPcNtbq4gMdbH6wXNxNXNBlOLyKs59aiFRoUEkxYYxf+M+PrvzNIZ0j+KVRdt49JMMRvSKZl12Ea//9CT+9/217D9YwXnDPccR1LY3qmvcrMsuol9CBNFdPG2vN5ftpLLaTUiQgwdmrQc801ZfumYsGTklXPnqMsoqarj9rAGcOSSRC59dDHh2fi/KzGN0nxi6RYXSIzqUOWtzsNZSUFbFoaoa/mdcEt2jQ/n7l5sxBi4d05srTk7i0hc8p5UOD3bicBhKyqt5ZNpwxiR3JavgUN25jlqbAl3kOOQUHWLiY/MBmHfXGXVXWaqsdhPkNA36qG8t38kDs9Zz3cRkzhvenStfXc60UT35++WjeXvFLpZs2U9ZZQ0Xj+7FlBO6H3Y1qNKKapwOc9yjuCN5bsEWnvx8EwBv3zSBif2/O3iqusbNuEfncdrABDL3lpC5r4ToLkEM7xnFWzdOYOmW/fRPjKg77TB4Tu425pG5TB7saZEcydz0XG6ankpEiIvrJ6Vwz3mDAcgtLmfyk1+RGBXCLaf358rxffh4bU5dC6U2uI+mxm25+PkllJRX88EvTqn7ubySCv44J52P1uwhLNhJkNPBWUMSmbU6m7BgJwvumVz3mlJ35POTl76hR3QXJvaPY8aqLKyFS0b34vcXDa97zEc/TqewrIoLTuzB9a9/C8CCeyY3uEBNW9Ch/yLHoXtUKLHhwXQJcjY4LUKw6/CR6KVjerM+u4irJiSTHBfGiF7RdacfvuLkPlxxcvMXEgfq2hxt6eyhiTz5+SaCnIbR3ksg1nI5HZw9pBszVnlaKP0SwtmWV1p3KuJJTZyGITI0iOeuHEO/Fpwy4txh3fjmt2eREBHSYCTfLSqUFQ+cTXiwq+7CJhec2IMLTuxxTK/N6TC8e/NEjKHBL8WEyBCeuXwUJ6d05eGP0vnNeYO5cGRPVmzP58bT+jb4BTUuJZZ3b5lIz5guRIW6+HpzHgmRIfz5khENHvOBCzw7Na21nNArisKyKlLiwo6p3tamEbpIC7yyaBuRoS4uP0og+wNrLac+sYCeMaG8f+ukw+7/bP1ebn1zJacPSuClq8fy6tfb+MlJSQ1Cz5+VVVbXne2zdif1kRSUVtIl2HnEv5pyig5RVllD/yZO19za1HIRkQbS9xQTGuRo8nzxFdU1PPHpJn56SgpJsb4dccrh1HIRkQbqT+FrLMTl5KEftv4caWl7OlJURCRAKNBFRAKEAl1EJEAo0EVEAoQCXUQkQCjQRUQChAJdRCRAKNBFRAKEz44UNcbkATu/54/HA/tbsZzW1FFrU13HpqPWBR23NtV1bL5vXcnW2oSm7vBZoB8PY0xqc4e++lpHrU11HZuOWhd03NpU17Fpi7rUchERCRAKdBGRAOGvgf6yrws4go5am+o6Nh21Lui4tamuY9PqdfllD11ERA7nryN0ERFpRIEuIhIg/C7QjTFTjDGbjDFbjDH3+bCOJGPMAmNMujFmgzHmDu/yPxhjso0xad6vqT6obYcxZp33+VO9y2KNMXONMZu9/3b1QV2D622XNGNMsTHmTl9sM2PMP40x+4wx6+sta3IbGY9nvJ+5tcaYMe1c15PGmI3e555ljInxLk8xxhyqt91ebOe6mn3fjDG/9W6vTcaY89qqriPU9m69unYYY9K8y9tzmzWXEW33ObPW+s0X4AS2Av2AYGANMMxHtfQAxnhvRwKZwDDgD8A9Pt5OO4D4Rsv+AtznvX0f8EQHeC/3Asm+2GbA6cAYYP3RthEwFfgUMMAEYHk71/UDwOW9/US9ulLqr+eD7dXk++b9f7AGCAH6ev/POtuztkb3/xV4yAfbrLmMaLPPmb+N0E8Gtlhrt1lrK4F3gGm+KMRam2OtXeW9XQJkAL18UUsLTQP+5b39L+BHvisFgLOBrdba73u08HGx1i4C8hstbm4bTQOmW49lQIwx5tguR38cdVlrv7DWVnu/XQb0bovnPta6jmAa8I61tsJaux3Yguf/brvXZowxwE+At9vq+ZtzhIxos8+ZvwV6L2B3ve+z6AAhaoxJAUYDy72Lfun9k+mfvmhtABb4whiz0hhzs3dZN2ttjvf2XqCbD+qq73Ia/ifz9TaD5rdRR/rc/QzPKK5WX2PMamPMQmPMaT6op6n3rSNtr9OAXGvt5nrL2n2bNcqINvuc+VugdzjGmAhgBnCntbYYeAHoD4wCcvD8udfeTrXWjgHOB35hjDm9/p3W8/edz+arGmOCgYuA972LOsI2a8DX26gpxpgHgGrgLe+iHKCPtXY0cBfwH2NM81d/bn0d7n1rwhU0HDi0+zZrIiPqtPbnzN8CPRtIqvd9b+8ynzDGBOF5o96y1s4EsNbmWmtrrLVu4BXa8E/N5lhrs73/7gNmeWvIrf3zzfvvvvauq57zgVXW2lzoGNvMq7lt5PPPnTHmeuBC4CpvCOBtaRzw3l6Jp1c9qL1qOsL75vPtBWCMcQGXAO/WLmvvbdZURtCGnzN/C/RvgYHGmL7eUd7lwGxfFOLtzb0GZFhrn6q3vH7P62JgfeOfbeO6wo0xkbW38exQW49nO13nXe064MP2rKuRBqMmX2+zeprbRrOBa72zECYARfX+ZG5zxpgpwG+Ai6y1ZfWWJxhjnN7b/YCBwLZ2rKu59202cLkxJsQY09db14r2qquec4CN1tqs2gXtuc2aywja8nPWHnt7W/MLz57gTDy/WR/wYR2n4vlTaS2Q5v2aCvwbWOddPhvo0c519cMzw2ANsKF2GwFxwJfAZmAeEOuj7RYOHACi6y1r922G5xdKDlCFp1d5Q3PbCM+sg+e8n7l1wLh2rmsLnt5q7efsRe+6l3rf4zRgFfDDdq6r2fcNeMC7vTYB57f3e+ld/gZwa6N123ObNZcRbfY506H/IiIBwt9aLiIi0gwFuohIgFCgi4gECAW6iEiAUKCLiAQIBbqISIBQoIuIBIj/Bw+TpjOwjmLjAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(torch.tensor(lossi).view(-1, 1000).mean(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "b19e0b76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.4125, 3.5151, 3.4015,  ..., 1.5967, 1.9766, 2.0802])"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(lossi).view(-1, 2).mean(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "a6ce6218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calibrate batch norm at the end of training\n",
    "with torch.no_grad():\n",
    "    emb = C[Xtr]\n",
    "    embcat = emb.view(emb.shape[0], -1)\n",
    "    hpreact = embcat @ W1 + b1\n",
    "    bnmean = hpreact.mean(0, keepdim=True)\n",
    "    bnvar = hpreact.var(0, keepdim=True, unbiased=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "0e0e932a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad\n",
    "def evaluate_loss(split):\n",
    "    X, Y = {\n",
    "        \"train\": (Xtr, Ytr),\n",
    "        \"dev\": (Xdev, Ydev),\n",
    "        \"test\": (Xte, Yte)\n",
    "    }[split]\n",
    "    emb = C[X]\n",
    "    embcat = emb.view(emb.shape[0], -1)\n",
    "    hpreact = embcat @ W1 + b1\n",
    "    hpreact = bngain * (hpreact - bnmean)* (bnvar+1e-5)**-0.5 + bnbias\n",
    "    \n",
    "    # non-linearity\n",
    "    h = torch.tanh(hpreact)\n",
    "    logits = h @ W2 + b2\n",
    "    loss = F.cross_entropy(logits, Y)\n",
    "    print(split, \"Loss=\", loss.item())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "67a39de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss= 1.7864493131637573\n",
      "dev Loss= 1.7827987670898438\n",
      "test Loss= 1.8062044382095337\n"
     ]
    }
   ],
   "source": [
    "evaluate_loss(\"train\")\n",
    "evaluate_loss(\"dev\")\n",
    "evaluate_loss(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "e3a807bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pler.\n",
      "woodpecker.\n",
      "earther.\n",
      "narnch.\n",
      "starbler.\n",
      "nuzbao.\n",
      "greer_tnaceeds_cry_burgemche_czudlightikz_oinchested_milpe_pen.\n",
      "pal.\n",
      "eantsas.\n",
      "maleenneds_suluckownd_stowe_buy.\n",
      "rufpes_anin.\n",
      "chathroatellowe_petelrssnyshrikeet.\n",
      "alarthel.\n",
      "whiteeyeatches.\n",
      "rctler.\n",
      "mouddatgew_whiteeye.\n",
      "eabird.\n",
      "pinetailes_cis_ifinch.\n",
      "pinian_boubler.\n",
      "oop.\n"
     ]
    }
   ],
   "source": [
    "# sample from the model\n",
    "\n",
    "\n",
    "for _ in range(20):\n",
    "    context = [0] * block_size\n",
    "    outs = []\n",
    "    while True:\n",
    "        emb = C[torch.tensor([context])]\n",
    "        embcat = emb.view(emb.shape[0], -1)\n",
    "        hpreact = embcat @ W1 + b1\n",
    "        hpreact = bngain * (hpreact - bnmean) * (bnvar + 1e-5)**-0.5 + bnbias\n",
    "        h = torch.tanh(hpreact)\n",
    "        logits = h @ W2 + b2\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        ix = torch.multinomial(probs, 1).item()\n",
    "        context = context[1:] + [ix]\n",
    "        outs.append(ix)\n",
    "        if ix == 0:\n",
    "            break\n",
    "    print(\"\".join(itos[i] for i in outs))\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66128e64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
